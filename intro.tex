
\section{Introduction}

This paper details the cryptographic techniques and protocols used by Cape Privacy's encrypted learning solution. We expect the reader to have some familiarity with secure multi-party computation, linear algebra, and ring arithmetic; as a good starting point we recommend \cite{evans2017pragmatic}. We also omit detailed explanations of machine learning and the models we support, instead referring the interested reader to~\cite{??}.

Note that this paper is currently scoped to the linear regression task outlined in section~\ref{??}. Future versions of the paper will expand upon this with additional models and protocols.


\subsection{Linear Regression}

We here focus on performing linear regression between a data provider and a model owner (or data subscriber). From a cryptographic perspective, this boils down to performing a matrix dot product on secret shared data to train the weights of the model. In addition, we also compute several metrics on secret shared data to measure the impact of the regression. Concretely, we compute the MSE (mean squared error)

In order to compute the MAPE (mean absolute percentage error) metric which boils down to compute
the absolute value of a secret $\share{|\vx|}$.

% \definecolor{codegreen}{rgb}{0,0.6,0}
% \definecolor{codegray}{rgb}{0.5,0.5,0.5}
% \definecolor{codepurple}{rgb}{0.58,0,0.82}
% \definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% \lstdefinestyle{mystyle}{
%     backgroundcolor=\color{backcolour},
%     commentstyle=\color{codegreen},
%     keywordstyle=\color{magenta},
%     numberstyle=\tiny\color{codegray},
%     stringstyle=\color{codepurple},
%     basicstyle=\ttfamily\footnotesize,
%     breakatwhitespace=false,
%     breaklines=true,
%     captionpos=b,
%     keepspaces=true,
%     numbers=left,
%     numbersep=5pt,
%     showspaces=false,
%     tabsize=2
% }

% \lstset{style=mystyle}

% \begin{lstlisting}[language=Python]
% @edsl.computation
% def lin_reg():

%     with x_owner:
%         X = edsl.load("X")
%         bias = edsl.ones(edsl.slice(edsl.shape(X), begin=0, end=1))
%         reshaped_bias = edsl.expand_dims(bias, 1)
%         X_b = edsl.concatenate([reshaped_bias, X], axis=1)
%         A = edsl.inverse(edsl.dot(edsl.transpose(X_b), X_b))
%         B = edsl.dot(A, edsl.transpose(X_b))

%     with y_owner:
%         y_true = edsl.load("y")
%         totals_ss = ss_tot(y_true)

%     with replicated:
%         w = edsl.dot(B, y_true)
%         y_pred = edsl.dot(X_b, w)
%         mse_result = mse(y_pred, y_true)
%         residuals_ss = ss_res(y_pred, y_true)

%     with x_owner:
%         rsquared_result = r_squared(residuals_ss, totals_ss)
%         w = edsl.identity(w)
%         mse = edsl.identity(mse)
%         residuals_ss = edsl.identity(residuals_ss)
% \end{lstlisting}

\commentM{TODO: briefly describe the usecase and its high-level computation. }

\commentM{TODO: insert eDSL snippet}

For the linear regression use-case we believe that $128$ bit field size is
enough using a fixed point precision by $16$ bits while keeping the numbers
magnitude to $40$ bits (thus making the integral part of size $24$ bits).

\input{replicated/fixed-point}
